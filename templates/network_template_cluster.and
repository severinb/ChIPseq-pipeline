/*----------Composite Components-----------*/

/*----------Foreground Function------------*/
function IPfunction(BinaryFile IN, string repFMIid, string iter, string DESC, string TFname, string formatFlag) -> (BinaryFolder IPout, Latex IPlog)
{

    if formatFlag == "bed" {

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_file = IN, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                     capt_plot1="Fragment size correlation plot",
                                     sectionTitle=TFname+": Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)

       pdfreport = CombineLatex(latex1=latexfrag.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       return record(IPout=fraglen.out_dir, IPlog=latexfrag.fragment)

    }


    else {

       ////quality filtering, transform and importSample //////
       if formatFlag == "fastq" {
          //Quality Filter: Filters out reads that are too short and have too many Ns.
          qualityfilter = SilviaQF(in_file = IN, pythonPATH="PYTHON_PATH", @host="long"QUALITYFILTER_iter)

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = qualityfilter.out_file, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = qualityfilter.out_file, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)

          latexfrag1 = LatexFragmentizer(plot1=qualityfilter.plot_before,
                                         plot2=qualityfilter.plot_after,
                                         capt_plot1="Read length reverse cumulative distribution before filtering",
                                         capt_plot2="Read length reverse cumulative distribution after filtering",
                                         sectionTitle=TFname+": Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle="Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)



       }

       if formatFlag == "fasta" {

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = IN, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = IN, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle=TFname+": Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


       }


       //Imports the sample into FMI repository (copies the fasta file there and creates some directories).
       import = importSample(in_file = trans.out_file, desc=DESC, FMIpath="FMI_PATH", FMIid = repFMIid, perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @host="long_hm"IMPORT_iter) 


       ////work from the samples repository: annotateSample, extract wig and bed and count mappable reads //////////////

       //Runs bowtie to map to genome and transcriptome  
       annotate = annotateSample(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=import, @host="verylong_hm"ANNOTATE_iter)
  
       //Extracts mappings in bedweight format (weight is number of identical reads/number of mapping positions)
       bedweight = extractBedweight(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BEDWEIGHT_iter)

       //extracting bed format file. It's location is the same as bedweight.
       //bed = extractBed(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", maxhits=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BED_iter)

       //Extracts mappings in wig format
       wig = extractWig(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, width=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"WIG_iter)

       //Counts how many reads were mapped
       mappable = numberMappableReads(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"MAPPABLE_iter)

       //Creates three plots with mapping statistics
       errorPlots = createErrorPlots(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"ERRORPLOTS_iter)


       ////Shift bed file, output from bed_i

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_dir = bedweight.out_dir, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag4 = LatexFragmentizer(log1=mappable.numberMappableReads_log, 
                                      plot1=errorPlots.error_profiles_plot,
                                      plot2=errorPlots.fraction_aligned_plot,
                                      plot3=errorPlots.repeatedness_plot,
                                      capt_log1="Number of mapped reads", 
                                      capt_plot1="Fraction of all reads that had an error at read position",
                                      capt_plot2="Fraction of all reads that have a certain mapping error up to read position",
                                      capt_plot3="Number of reads that have a certain number of hits",
                                      sectionTitle="Mappging:", @host="noQueue"LATEXFRAG_iter)

       latexfrag5 = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                      capt_plot1="Fragment size correlation plot",
                                      sectionTitle="Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)


       if formatFlag == "fastq" {

       pdfreport = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }

       if formatFlag == "fasta" {

       pdfreport = CombineLatex(latex1=latexfrag2.fragment, latex2=latexfrag3.fragment, latex3=latexfrag4.fragment, latex4=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }


       return record(IPout=fraglen.out_dir, IPlog=latexfrag2.fragment)

    }

}


/*----------Background Function------------*/
function BGfunction(BinaryFile bgIN, string repFMIid, string iter, string DESC, string TFname, string formatFlag) -> (BinaryFolder BGout, Latex BGlog)
{

    if formatFlag == "bed" {

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_file = bgIN, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                     capt_plot1="Fragment size correlation plot",
                                     sectionTitle=TFname+": Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)

       pdfreport = CombineLatex(latex1=latexfrag.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       return record(BGout=fraglen.out_dir, BGlog=latexfrag.fragment)

    }


    else {

       ////quality filtering, transform and importSample //////
       if formatFlag == "fastq" {
          //Quality Filter: Filters out reads that are too short and have too many Ns.
          qualityfilter = SilviaQF(in_file = bgIN, pythonPATH="PYTHON_PATH", @host="long"QUALITYFILTER_iter)

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = qualityfilter.out_file, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = qualityfilter.out_file, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)

          latexfrag1 = LatexFragmentizer(plot1=qualityfilter.plot_before,
                                         plot2=qualityfilter.plot_after,
                                         capt_plot1="Read length reverse cumulative distribution before filtering",
                                         capt_plot2="Read length reverse cumulative distribution after filtering",
                                         sectionTitle=TFname+": Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle="Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)



       }

       if formatFlag == "fasta" {

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = bgIN, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = bgIN, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle=TFname+": Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


       }


       //Imports the sample into FMI repository (copies the fasta file there and creates some directories).
       import = importSample(in_file = trans.out_file, desc=DESC, FMIpath="FMI_PATH", FMIid = repFMIid, perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @host="long_hm"IMPORT_iter) 


       ////work from the samples repository: annotateSample, extract wig and bed and count mappable reads //////////////

       //Runs bowtie to map to genome and transcriptome  
       annotate = annotateSample(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=import, @host="verylong_hm"ANNOTATE_iter)
  
       //Extracts mappings in bedweight format (weight is number of identical reads/number of mapping positions)
       bedweight = extractBedweight(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BEDWEIGHT_iter)

       //extracting bed format file. It's location is the same as bedweight.
       //bed = extractBed(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", maxhits=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BED_iter)

       //Extracts mappings in wig format
       wig = extractWig(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, width=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"WIG_iter)

       //Counts how many reads were mapped
       mappable = numberMappableReads(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"MAPPABLE_iter)

       //Creates three plots with mapping statistics
       errorPlots = createErrorPlots(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"ERRORPLOTS_iter)


       ////Shift bed file, output from bed_i

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_dir = bedweight.out_dir, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)


       latexfrag4 = LatexFragmentizer(log1=mappable.numberMappableReads_log, 
                                      plot1=errorPlots.error_profiles_plot,
                                      plot2=errorPlots.fraction_aligned_plot,
                                      plot3=errorPlots.repeatedness_plot,
                                      capt_log1="Number of mapped reads", 
                                      capt_plot1="Fraction of all reads that had an error at read position",
                                      capt_plot2="Fraction of all reads that have a certain mapping error up to read position",
                                      capt_plot3="Number of reads that have a certain number of hits",
                                      sectionTitle="Mappging:", @host="noQueue"LATEXFRAG_iter)

       latexfrag5 = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                      capt_plot1="Fragment size correlation plot",
                                      sectionTitle="Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)


       if formatFlag == "fastq" {

       pdfreport = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }

       if formatFlag == "fasta" {

       pdfreport = CombineLatex(latex1=latexfrag2.fragment, latex2=latexfrag3.fragment, latex3=latexfrag4.fragment, latex4=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }


       return record(BGout=fraglen.out_dir, BGlog=latexfrag2.fragment)


    }

}

/*-----------------------------------------------------------------------------------------------------------------*/
/*------------------------------Composite Component for processing on TF-Background pair---------------------------*/
/*-----------------------------------------------------------------------------------------------------------------*/

function FGBGprocessing(string IPstring, string BGstring, string TFname) -> (BinaryFile Sequences, BinaryFolder RegionCoverageDir, BinaryFile PeakStats, BinaryFolder PeakCallDir, BinaryFile LLog, BinaryFile LLog_tops, BinaryFile AUCLog, BinaryFile AUCLog_tops, BinaryFile Peaks, BinaryFile ShuffledTestSet, BinaryFile ShuffledTrainSet, BinaryFile TestSet, BinaryFile TrainingSet, BinaryFile UFEmodel, BinaryFile BaseFrequencies){



         ////Doing all the read counting and BG cut-off filtering with Piotr's binReads.pl
         binreads = BinReads(FGfiles_string = IPstring, BGfiles_string = BGstring, chrominfo="CHROMINFOFILE_PATH", perlPATH="PERL_PATH", FGwinsize=FG_WINSIZE, BGwinsize=BG_WINSIZE, stepsize=STEPSIZE, FMIpath="FMI_PATH", @host="long_hm")

         bg_filter = FilterBGwin(infile = binreads.out_file, bg_cutoff=-99, perlPATH="PERL_PATH", @host="long_hm")

         peakcall_newnoise = PeakCall_newNoiseModel(in_file = bg_filter.outfile, perlPATH="PERL_PATH", R_LIBS_USER="R_LIBS_USER_PATH", @host="long_hm")

         //Find a cut-off on z-scores by constraining FDR
         find_z_cutoff = zCutOff_byFDR(in_dir = peakcall_newnoise.out_dir, FDR=FDRVALUE, @host="long")

         //Merges all overlapping widnows above a Z-value cut-off 
         peakmerge = PeakMerger(in_dir = peakcall_newnoise.out_dir, z_cutoff_infile = find_z_cutoff.z_cutoff_file, z_cutoff=-1, topPeaks=1000, @host="long")

         //Computes basepair coverage for each region (how many foreground reads voer each bp).
         regioncoverage = RegionCoverage(regions = peakmerge.allpeaks, read_files = IPstring, BedToolsPath="BEDTOOLS_PATH", regionlength=-1, toFraglength="true", @host="long_hm")

         //This thing will submit array jobs itself
	 //quene_name="long", here long stands for the actual queue name and nor for the alias from hosts.conf used by anduril!
         selectpeaks = SelectPeaksMM(in_dir = regioncoverage.out_dir, FGfiles_string=IPstring, FragmentLength=-1, files_per_job=50, order=4, widthFactor=1, project_leader="PROJECTLEADER", RMSD_cutoff=100, topPeaks=2000, queue_name="fs_long")


         //Recompute Z-scores for refined peaks
         recompz = RecomputeZscores(peakfile = selectpeaks.allpeaks, peakstats = selectpeaks.peakstats, binned_reads = bg_filter.outfile, fit_log = peakcall_newnoise.log_file, Z_cutoff_file = peakmerge.z_cutoff_file, read_files=IPstring, FGwinsize=FG_WINSIZE, Z_cutoff=-1, topPeaks=2000, @host="long_hm")


         repeatsout = RepeatsOut(peaks = recompz.outfile, repeatPath="REPEAT_PATH", BedToolsPath="BEDTOOLS_PATH", @host="long_hm")

         //annotate peaks to genes etc, do GO analysis etc... using HOMER
         //annotregions = AnnotateRegions(regions = recompz.allpeaks, genome="GENOME", homerPATH="HOMER_PATH", @host="long")
         
         //annotate peaks to promoters and thus to genes...
         annotpeaks = AnnotatePeaks(peaks = recompz.allpeaks, genome="GENOME", annotationFile="ANNOTATION_FILE", @host="long")

         pstats = recompz.peakstats

         //Aligns regions to some related species
         alignpeaks = AlignPeaks(in_file = repeatsout.out_file, genome="GENOME", AlignPipePath="ALIGN_PIPE_PATH")

         //Extracts sequences from region coordinates
         getseqs = GetSequences(in_file = repeatsout.out_file, genome="GENOME", genome_path="GENDIR_PATH", @host="long")

         //Splits alignments/sequences in two halfs. Both halfs have equally high Z-value scoring regions.
         splitalignments = SplitTestTrain(infile = alignpeaks.AlignedPeaks, @host="long")
         splitseqs = SplitTestTrain(infile = getseqs.Sequences, @host="long")

         //Shuffles Alignments/Sequences to produce a background.
         shuffledAlns_test = ShuffleAlignments(infile = splitalignments.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")
         shuffledAlns_train = ShuffleAlignments(infile = splitalignments.even_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")

         shuffledSeqs_test = ShuffleAlignments(infile = splitseqs.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")
         shuffledSeqs_train = ShuffleAlignments(infile = splitseqs.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")


         getseqs2 = GetSequences(in_file = peakmerge.allpeaks, genome="GENOME", genome_path="GENDIR_PATH", @host="long")


         //Fork here if no de novo motif finding is requested. Also, for a given WM library enrichment is checked and statistics for enriched WMs will be calculated.

         pipeFlag = "PIPEFLAG"

         if pipeFlag == "JUSTPEAKS" {
             
                  latexfrag1 = LatexFragmentizer(log1=bg_filter.log_file,
                                                 plot1=bg_filter.plotfile,
                                                 capt_log1="",
                                                 capt_log2="Reverse Cumulative Distribution of Background Window Counts.",
                                                 sectionTitle=TFname+": Filtering of Background Read Counts:")

                  latexfrag2 = LatexFragmentizer(log1=peakcall_newnoise.log_file,
                                                 plot1=peakcall_newnoise.Z_hist,
                                                 capt_log1="",
                                                 capt_plot1="Distribution of Window Z-values with Fitted Gaussian.",
                                                 sectionTitle="Fitting Background Noise Distribution:")

                  latexfrag3 = LatexFragmentizer(log1=peakmerge.PeakMerger_log,
                                                 plot1=find_z_cutoff.revcum,
                                                 capt_log1="",
                                                 capt_plot1="Reverse Cumulative Distribution of Window Z-values.",
                                                 sectionTitle="Determining Z-value Cut-off and Mergeing Windows:")

                  latexfrag4 = LatexFragmentizer(log1=selectpeaks.log_file,
                                                 plot1=selectpeaks.height_sigma_scatter,
                                                 //plot2=selectpeaks.height_rmsd_scatter,
                                                 //plot3=selectpeaks.sigma_rmsd_scatter,
                                                 plot4=selectpeaks.height_revcum,
                                                 //plot5=selectpeaks.rmsd_hist,
                                                 plot6=selectpeaks.sigma_hist,
                                                 capt_log1="",
                                                 capt_plot1="Scatter plot of peak height versus peak width",
                                                 //capt_plot2="Scatter plot of peak height versus peak quality",
                                                 //capt_plot3="Scatter plot of peak width versus peak quality",
                                                 capt_plot4="Reverse cumulative distribution of peak heights",
                                                 //capt_plot5="Histogram of peak qualities",
                                                 capt_plot6="Histogram of peak widths (sigmas)",
                                                 sectionTitle="Refining Peaks (Gaussian Mixture Modelling):")

                  latexfrag5 = LatexFragmentizer(log1=recompz.log_file,
                                                 plot1=recompz.height_z_scatter,
                                                 plot2=recompz.z_hist,
                                                 plot3=recompz.z_revcum,
                                                 capt_log1="",
                                                 capt_plot1="Scatter plot of peak height versus peak Z-score",
                                                 capt_plot2="Histogram of peak Z-scores",
                                                 capt_plot3="Reverse cumulative of peak Z-scores",
                                                 sectionTitle="Computing Z-scores of Refined Peaks:")

                  latexfrag6 = LatexFragmentizer(log1=annotpeaks.log_file,
                                                 capt_log1="",
                                                 sectionTitle="Annotating Refined Peaks:")


                  combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment)      
                  OUTPUT(combine2.pdfreport)
                  OUTPUT(annotpeaks.peakAnnotations)

                  //All outports are dummy ports:
                  return record(Sequences = getseqs2.Sequences, RegionCoverageDir = regioncoverage.out_dir, PeakStats = pstats, PeakCallDir = peakcall_newnoise.out_dir, LLog = pstats, LLog_tops = pstats, AUCLog = pstats, AUCLog_tops = pstats, Peaks = annotpeaks.peakAnnotations, ShuffledTestSet = shuffledSeqs_test.outfile, ShuffledTrainSet = shuffledSeqs_train.outfile, TestSet = splitseqs.odd_file, TrainingSet = splitseqs.even_file, UFEmodel = buildufe.UFEmodel, BaseFrequencies = buildufe.BaseFrequencies)

                      }


         //Runs PhyloGibbs
         phylogibbs1 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=10, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs2 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=15, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs3 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=20, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")


/*phylogibbs without taking alignments into account*/

         phylogibbs4 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=10, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs5 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=15, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs6 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=20, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

	 //Refine the resulted WMs from Phylogibbs
	 refinedMotifPG1_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs1.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG1_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs1.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG2_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs2.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG2_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs2.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG3_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs3.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG3_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs3.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG4_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs4.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG4_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs4.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG5_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs5.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG5_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs5.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG6_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs6.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG6_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs6.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 

         //Report generation

         latexfrag1 = LatexFragmentizer(log1=bg_filter.log_file,
                                        plot1=bg_filter.plotfile,
                                        capt_log1="",
                                        capt_log2="Reverse Cumulative Distribution of Background Window Counts.",
                                        sectionTitle=TFname+": Filtering of Background Read Counts:")

         latexfrag2 = LatexFragmentizer(log1=peakcall_newnoise.log_file,
                                        plot1=peakcall_newnoise.Z_hist,
                                        capt_log1="",
                                        capt_plot1="Distribution of Window Z-values with Fitted Gaussian.",
                                        sectionTitle="Fitting Background Noise Distribution:")

         latexfrag3 = LatexFragmentizer(log1=peakmerge.PeakMerger_log,
                                        plot1=find_z_cutoff.revcum,
                                        capt_log1="Bin Reads Log",
                                        capt_plot1="Reverse Cumulative Distribution of Window Z-values.",
                                        sectionTitle="Determining Z-value Cut-off and Mergeing Windows:")

         latexfrag4 = LatexFragmentizer(log1=selectpeaks.log_file,
                                        plot1=selectpeaks.height_sigma_scatter,
                                        //plot2=selectpeaks.height_rmsd_scatter,
                                        //plot3=selectpeaks.sigma_rmsd_scatter,
                                        plot4=selectpeaks.height_revcum,
                                        //plot5=selectpeaks.rmsd_hist,
                                        plot6=selectpeaks.sigma_hist,
                                        capt_log1="",
                                        capt_plot1="Scatter plot of peak height versus peak width",
                                        //capt_plot2="Scatter plot of peak height versus peak quality",
                                        //capt_plot3="Scatter plot of peak width versus peak quality",
                                        capt_plot4="Reverse cumulative distribution of peak heights",
                                        //capt_plot5="Histogram of peak qualities",
                                        capt_plot6="Histogram of peak widths (sigmas)",
                                        sectionTitle="Refining Peaks (Gaussian Mixture Modelling):")

         latexfrag5 = LatexFragmentizer(log1=recompz.log_file,
                                        plot1=recompz.height_z_scatter,
                                        plot2=recompz.z_hist,
                                        plot3=recompz.z_revcum,
                                        capt_log1="",
                                        capt_plot1="Scatter plot of peak height versus peak Z-score",
                                        capt_plot2="Histogram of peak Z-scores",
                                        capt_plot3="Reverse cumulative of peak Z-scores",
                                        sectionTitle="Computing Z-scores of Refined Peaks:")

         latexfrag6 = LatexFragmentizer(log1=annotpeaks.log_file,
                                        capt_log1="",
                                        sectionTitle="Annotating Refined Peaks:")

         latexfragPG = LatexFragmentizer(plot1=phylogibbs1.Logo1,
                                         plot2=phylogibbs1.Logo2,
                                         plot3=phylogibbs2.Logo1,
                                         plot4=phylogibbs2.Logo2,
                                         plot5=phylogibbs3.Logo1,
                                         plot6=phylogibbs3.Logo2,
                                         plot7=phylogibbs4.Logo1,
                                         plot8=phylogibbs4.Logo2,
                                         plot9=phylogibbs5.Logo1,
                                         plot10=phylogibbs5.Logo2,
                                         plot11=phylogibbs6.Logo1,
                                         plot12=phylogibbs6.Logo2,
                                         capt_plot1="Phylogibbs motif 1. Window length = 10, with alignments",
                                         capt_plot2="Phylogibbs motif 2. Window length = 10, with alignments",
                                         capt_plot3="Phylogibbs motif 3. Window length = 15, with alignments",
                                         capt_plot4="Phylogibbs motif 4. Window length = 15, with alignments",
                                         capt_plot5="Phylogibbs motif 5. Window length = 20, with alignments",
                                         capt_plot6="Phylogibbs motif 6. Window length = 20, with alignments",
                                         capt_plot7="Phylogibbs motif 7. Window length = 10, no alignments",
                                         capt_plot8="Phylogibbs motif 8. Window length = 10, no alignments",
                                         capt_plot9="Phylogibbs motif 9. Window length = 15, no alignments",
                                         capt_plot10="Phylogibbs motif 10. Window length = 15, no alignments",
                                         capt_plot11="Phylogibbs motif 11. Window length = 20, no alignments",
                                         capt_plot12="Phylogibbs motif 12. Window length = 20, no alignments",
                                         sectionTitle="Logos of All Twelve de novo Motifs:") 

         latexfragMot = LatexFragmentizer(plot1=refinedMotifPG1_1.Logo,
                                          plot2=refinedMotifPG1_2.Logo,
                                          plot3=refinedMotifPG2_1.Logo,
                                          plot4=refinedMotifPG2_2.Logo,
                                          plot5=refinedMotifPG3_1.Logo,
                                          plot6=refinedMotifPG3_2.Logo,
                                          plot7=refinedMotifPG4_1.Logo,
                                          plot8=refinedMotifPG4_2.Logo,
                                          plot9=refinedMotifPG5_1.Logo,
                                          plot10=refinedMotifPG5_2.Logo,
                                          plot11=refinedMotifPG6_1.Logo,
                                          plot12=refinedMotifPG6_2.Logo,
                                          capt_plot1="Refined logo for PhyloGibbs motif 1. Window length = 10, with alignments",
                                          capt_plot2="Refined logo for PhyloGibbs motif 2. Window length = 10, with alignments",
                                          capt_plot3="Refined logo for PhyloGibbs motif 3. Window length = 15, with alignments",
                                          capt_plot4="Refined logo for PhyloGibbs motif 4. Window length = 15, with alignments",
                                          capt_plot5="Refined logo for PhyloGibbs motif 5. Window length = 20, with alignments",
                                          capt_plot6="Refined logo for PhyloGibbs motif 6. Window length = 20, with alignments",
                                          capt_plot7="Refined logo for PhyloGibbs motif 7. Window length = 10, no alignments",
                                          capt_plot8="Refined logo for PhyloGibbs motif 8. Window length = 10, no alignments",
                                          capt_plot9="Refined logo for PhyloGibbs motif 9. Window length = 15, no alignments",
                                          capt_plot10="Refined logo for PhyloGibbs motif 10. Window length = 15, no alignments",
                                          capt_plot11="Refined logo for PhyloGibbs motif 11. Window length = 20, no alignments",
                                          capt_plot12="Refined logo for PhyloGibbs motif 12. Window length = 20, no alignments",
                                          sectionTitle="Logos for All Twelve Refined de novo Motifs.")




         filterwms = FilterWMs(WM1 = phylogibbs1.WeightMatrix1,
                               WM2 = refinedMotifPG1_1.refWM,
                               WM3 = phylogibbs1.WeightMatrix2,
                               WM4 = refinedMotifPG1_2.refWM,
                               WM5 = phylogibbs2.WeightMatrix1,
                               WM6 = refinedMotifPG2_1.refWM,
                               WM7 = phylogibbs2.WeightMatrix2,
                               WM8 = refinedMotifPG2_2.refWM,
                               WM9 = phylogibbs3.WeightMatrix1,
                               WM10 = refinedMotifPG3_1.refWM,
                               WM11 = phylogibbs3.WeightMatrix2,
                               WM12 = refinedMotifPG3_2.refWM,
                               WM13 = phylogibbs4.WeightMatrix1,
                               WM14 = refinedMotifPG4_1.refWM,
                               WM15 = phylogibbs4.WeightMatrix2,
                               WM16 = refinedMotifPG4_2.refWM,
                               WM17 = phylogibbs5.WeightMatrix1,
                               WM18 = refinedMotifPG5_1.refWM,
                               WM19 = phylogibbs5.WeightMatrix2,
                               WM20 = refinedMotifPG5_2.refWM,
                               WM21 = phylogibbs6.WeightMatrix1,
                               WM22 = refinedMotifPG6_1.refWM,
                               WM23 = phylogibbs6.WeightMatrix2,
                               WM24 = refinedMotifPG6_2.refWM,
                               @host="long")
     
         
         enrichmentScores_for_all = EnrichmentScores(TrainingSequences=splitseqs.odd_file,
                                    TrainingDecoySequences=shuffledSeqs_train.outfile, 
  				    TestSequences=splitseqs.even_file, 
  				    TestDecoySequences=shuffledSeqs_test.outfile, 
  				    DenovoWMs=filterwms.WMdir, 
  				    DatabaseWMs="WMLIBRARY", 
  				    genome="GENOME",
                                    CombinedMotifs="false")



         reducewms = ReduceWMs(infile=enrichmentScores_for_all.EnrichmentScores,
                     distance_cutoff=0.2,
                     minscore=0.0,
                     @host="long")


         WMlibrary = "WMLIBRARY"
         WMlib = INPUT(path = WMlibrary)



         //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
         wmqual_tops = WMQuality(train_set = splitseqs.even_file,
                                 bg_train_set = shuffledSeqs_train.outfile,
                                 test_set = splitseqs.odd_file,
                                 bg_test_set = shuffledSeqs_test.outfile,
                                 WMlist = enrichmentScores_for_all.EnrichmentScores,
                            	 aligned="false", genome="GENOME",
                            	 motevo_path="MOTEVO_PATH",
                            	 @host="long")


         enrichmentScores_combined_motifs = EnrichmentScores(TrainingSequences=splitseqs.odd_file,
                                            TrainingDecoySequences=shuffledSeqs_train.outfile, 
  				            TestSequences=splitseqs.even_file, 
  				            TestDecoySequences=shuffledSeqs_test.outfile, 
  				            DenovoWMs=reducewms.WMdir, 
  				            genome="GENOME",
                                            CombinedMotifs="true")



         //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
         wmqual = WMQuality(train_set = splitseqs.even_file,
                            bg_train_set = shuffledSeqs_train.outfile,
                            test_set = splitseqs.odd_file,
                            bg_test_set = shuffledSeqs_test.outfile,
                            WMlist = enrichmentScores_combined_motifs.EnrichmentScores,
                            aligned="false", genome="GENOME",
                            motevo_path="MOTEVO_PATH",
                            @host="long")


         latexfrag8 = LatexFragmentizer(plot1=wmqual.sens_ppv,
                                        capt_plot1="Sensitivity - positive predictive value plot of 4 best performing motifs",
                                        sectionTitle="Precision and Recall Plots of Four Best Performing Motifs:")


         latexfrag9 = LatexFragmentizer(//log1=site_enrichment.loglik_combined,
                                        plot1=site_enrichment.loglik_plot,
                                        //capt_log1="",
                                        capt_plot1="Contribution of motifs to ChIP peak explanantion.",
                                        sectionTitle="Final Motifs and Their Contribution in Explaining the Peaks:")



         combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment, latex7=latexfragPG.fragment, latex8=latexfragMot.fragment, latex9=latexfrag8.fragment, latex10=latexfrag9.fragment)
         OUTPUT(combine2.pdfreport)



         return record(Sequences = getseqs2.Sequences, RegionCoverageDir = regioncoverage.out_dir, PeakStats = pstats, PeakCallDir = peakcall_newnoise.out_dir, LLog = site_enrichment.loglik_contributing_motifs, LLog_tops = site_enrichment_slim.loglik_top_motifs, AUCLog = wmqual.log_file, AUCLog_tops = wmqual_tops.log_file, Peaks = annotpeaks.peakAnnotations, ShuffledTestSet = shuffledSeqs_test.outfile, ShuffledTrainSet = shuffledSeqs_train.outfile, TestSet = splitseqs.odd_file, TrainingSet = splitseqs.even_file, UFEmodel = buildufe.UFEmodel, BaseFrequencies = buildufe.BaseFrequencies)


}


/*-----------------------------------------------------------------------------------------------------------------*/
/*-----------------------Composite Component to compute statistics for each candidate WM---------------------------*/
/*-----------------------------------------------------------------------------------------------------------------*/



function GetWMStats(BinaryFile Sequences, BinaryFile TrainingSet, BinaryFile ShuffledTrainSet, BinaryFolder RegionCoverage, BinaryFile PeakStats, BinaryFile CandWM, BinaryFolder PeakCallDir, BinaryFile LLog, BinaryFile AUCLog, string IP_string) -> (BinaryFile Peakstats, BinaryFile TFBSstats) {


             WMlibrary = "WMLIBRARY"

             identifymotif = IdentifyMotif(WM = CandWM, WMlibrary=WMlibrary, ntop=4, mylogo_path="MYLOGO_PATH", @host="long")

             createlogo = CreateLogo(WM = CandWM, llog = LLog, auclog = AUCLog, mylogo_path="MYLOGO_PATH")

             getpeakposts = GetPeakPosteriors(regions = Sequences, 
                                              train_set = TrainingSet,
                                              bg_train_set = ShuffledTrainSet,
                                              RegCov_dir = RegionCoverage,
                                              statsfile = PeakStats,
                                              WM = CandWM,
                                              minposterior=0.2, motevo_path="MOTEVO_PATH", genome="GENOME", project_leader="PROJECTLEADER", files_per_job=1000,
                                              read_files=IP_string,
                                              queue_name_motevo="fs_long@@x3755",
                                              queue_name="fs_long@@x3755")


             getstats = GetStatistics(peakstats = getpeakposts.peakstats, TFBSstats = getpeakposts.TFBSstats, RegCov_dir = RegionCoverage, minposterior=0.2, @host="long")


             latexfrag1 = LatexFragmentizer(log1=identifymotif.top_motifs,
                                            log2=createlogo.log_file,
                                            plot1=createlogo.Logo,
                                            plot2=createlogo.sens_spec,
                                            capt_log1="4 Top Similar Looking Motifs:",
                                            capt_log2="Statistics:",
                                            capt_plot1="Logo of Weight Matrix",
                                            capt_plot2="Precision and Recall curve",
                                            sectionTitle="General Motif Characteristics:")

             latexfrag2 = LatexFragmentizer(log1=getstats.log_file,
                                            plot1=getstats.zscore_post_scatter,
                                            //plot2=getstats.quality_post_scatter,
                                            plot3=getstats.zscore_post_violin,
                                            //plot4=getstats.quality_post_violin,
                                            plot5=getstats.post_hist,
                                            //plot6=getstats.post_cumulative,
                                            plot7=getstats.TFBS_peakcenter_dist_hist,
                                            //plot8=getstats.TFBS_post_peakcenter_dist_scatter,
                                            plot9=getstats.coverage_histograms,
                                            capt_log3="",
                                            capt_plot1="Scatter plot of peak Z-score versus number of binding sites at peak",
                                            //capt_plot2="Scatter plot of peak quality versus number of binding sites at peak",
                                            capt_plot3="Violin plot of peak Z-score versus number of binding sites at peak",
                                            //capt_plot4="Violin plot of peak quality versus number of binding sites at peak",
                                            capt_plot5="Histogram of number of binding sites at peaks",
                                            //capt_plot6="Cumulative distribution of number of binding sites at peaks",
                                            capt_plot7="Histogram of distances of TFBS to its nearest peak center",
                                            //capt_plot8="Scatter plot of TFBS posterior versus distance to its nearest peak center",
                                            capt_plot9="Histograms of coverage at sites and in total regions",
                                            sectionTitle="Statistics for TFBS - Peak Centering and Peak Posterior - Peak Height Correlation:")



             combineWM = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment) //, latex4=latexfrag4.fragment)

             OUTPUT(combineWM.pdfreport)

             return record(Peakstats = getpeakposts.peakstats, TFBSstats = getpeakposts.TFBSstats)

}



/*----------------------------------------------------------------------------------------------------------------------------------*/
/*----------------------------------------------------Main function-----------------------------------------------------------------*/
/*----------------------------------------------------------------------------------------------------------------------------------*/


/*----------------1. Read in data--------------------*/

datafiles = INPUT(path="CSV_DATAFILE_PATH")
existingSamples = INPUT(path="CSV_EXISTING_SAMPLES")


TFrecord = record() 
TFrecordStrings = record() //This is the record for already processed replicates. The strings are thus shifted bedweight files

//Add the BG key, in case there is no background given. Otherwise it will complain below when starting FGBGprocessing.
TFrecordStrings["BG"] = ""
  
//initialize TFrecordString (contains string with paths to the shifted bedfiles)
//initilaize TFrecord with records for each input replicate

for file : std.itercsv(datafiles.in){
	TFrecordStrings[file.mode] = ""
	TFrecord[file.mode] = record()   
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))

////Reading from existingSamples.csv to add shifted.bedweight files to corresponding string.
for file : std.itercsv(existingSamples.in){
           TFrecordStrings[file.mode] = ""
           TFrecord[file.mode] = record()
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))

for file : std.itercsv(existingSamples.in){
           TFrecordStrings[file.mode] = TFrecordStrings[file.mode] + file.filepath + " "
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))


/*----------------2. process replicates, i.e. get shifted bedweight files--------------------*/

ip = 0
bg = 0

count_record = record()
//initialize count record. I need count_record so that every TF gets numbered from 1 onwards.
for file: std.itercsv(datafiles.in){
          count_record[file.mode] = 0
          }

for file : std.itercsv(datafiles.in){
	if file.mode != "BG" {
		count_record[file.mode] = count_record[file.mode] + 1
                ip = ip + 1

                fastq = INPUT(path=file.filepath, @name="fastq"+ip)
                fastq_i = std.lookup("fastq"+ip)

		IP = IPfunction(fastq_i.in, repFMIid = file.FMIid, iter = "IP"+ip, DESC = file.desc, TFname=file.mode, formatFlag=file.format, @name=file.mode + "_" + count_record[file.mode])
		IP_i = std.lookup(file.mode + "_" + count_record[file.mode])

		TFrecord[file.mode][ip] = IP_i.IPout

		}

	else {
		bg = bg + 1
		bg_fastq = INPUT(path=file.filepath, @name="bg_fastq"+bg)
                bg_fastq_i = std.lookup("bg_fastq"+bg)

		BG = BGfunction(bg_fastq_i.in, repFMIid = file.FMIid, iter = "BG"+bg, DESC = file.desc, TFname="Background", formatFlag=file.format, @name=file.mode + "_" + bg)
		BG_i = std.lookup(file.mode + "_" + bg)
 
		TFrecord[file.mode][bg] = BG_i.BGout

		}
}

//putting all shifted bedweight file paths from TFrecord into TFrecordStrings
for key, value : TFrecord{

	for key1, value1 : value{

		for k : std.iterdir(value1){
			TFrecordStrings[key] = TFrecordStrings[key] + " " + k.path
			}
		}
	}



/*-----------3. Start downstream processing of foreground and background samples------------*/

/*-------3.1 First find peaks and candidate WMs---------*/

FGBGOUT = record()
PEAKS_record = record()
for TF, str : TFrecordStrings{
	if TF != "BG"{
		proc = FGBGprocessing(IPstring = str, BGstring = TFrecordStrings["BG"],  TFname = TF, @name=TF + "_FgBg")
		proc_i = std.lookup(TF + "_FgBg")
		FGBGOUT[TF] = proc_i

                PEAKS_record[TF] = record()
                PEAKS_record[TF]["peaks"] = proc_i.Peaks

		}
	}

std.echo(std.recordToString(FGBGOUT))

pipeFlag = "PIPEFLAG"

//always use non aligned peaks, i.e. sequences
aligned_flag = "false"


/*-------3.2 Now get statistics for candidate WMs (de novo motifs) if requested---------*/

if pipeFlag != "JUSTPEAKS" {

          for TF, outvals : FGBGOUT{

              //To enable the pipe-line to run this loop parallely, first collect output and later parse it.
              Peak_stats_record = {}
              TFBSs_stats_record = {}

              wmiter = 0

              for candwm : std.itercsv(outvals.LLog){
        
                wmiter = wmiter + 1

                CandWM = INPUT(path=candwm.WM_path, @name=TF+"_WM_"+wmiter)
                CandWM_i = std.lookup(TF+"_WM_"+wmiter)


                stets = GetWMStats(outvals.Sequences, outvals.TrainingSet, outvals.ShuffledTrainSet, outvals.RegionCoverageDir, outvals.PeakStats, CandWM_i.in, outvals.PeakCallDir, outvals.LLog, outvals.AUCLog, IP_string = TFrecordStrings[TF], @name=TF+"_WMstats_"+wmiter)
                stets_i = std.lookup(TF+"_WMstats_"+wmiter)

                Peak_stats_record[candwm.WM_path] = stets_i.Peakstats
                TFBSs_stats_record[candwm.WM_path] = stets_i.TFBSstats

              }

              //used to plot correlation of predictions and to combine sites of all motifs in peak file.
              Peak_stats_record_strings = {}
              for wmpath, wmport : Peak_stats_record{
		  for k : std.iterdir(wmport){
                      Peak_stats_record_strings[wmpath] = k.path + "/" + k.name
                  }
              }
              Peak_stats_string = std.recordToString(Peak_stats_record_strings, valueSep=" ", itemSep=" ; ", keys=true, values=true)

              TFBSs_stats_record_strings = {}
              for wmpath, wmport : TFBSs_stats_record{
                  for k : std.iterdir(wmport){
                      TFBSs_stats_record_strings[wmpath] = k.path + "/" + k.name
                  }
              }
              TFBSs_string = std.recordToString(TFBSs_stats_record_strings, valueSep=" ", itemSep=" ; ", keys=true, values=true)

              PEAKS_record[TF]["peakstats"] = Peak_stats_string
              PEAKS_record[TF]["tfbs"] = TFBSs_string

          }


          for TF, peaks_tfbs : PEAKS_record{

              // produce the final output file just with known motifs:

              combinepeakstfbs = CombinePeaksTFBSs(peaks = peaks_tfbs["peaks"], TFBSs_string=peaks_tfbs["tfbs"], peakposts_string=peaks_tfbs["peakstats"], minposterior=0.2, FGfiles_string=TFrecordStrings[TF], @host="long", @name=TF+"_combinepeakstfbs")
              combinepeakstfbs_i = std.lookup(TF+"_combinepeakstfbs")

              motif_correlation = MotifCorrelation(peakstats_string = peaks_tfbs["peakstats"], @host="long", @name=TF+"_motif_correlation")
              motif_correlation_i = std.lookup(TF+"_motif_correlation")
              OUTPUT(motif_correlation_i.correlation_plot)
          }


          for TF, outvals : FGBGOUT{

	      wmiter = 0

	      for candwm : std.itercsv(outvals.LLog_tops) {
	      	  wmiter = wmiter + 1

                  CandWM = INPUT(path=candwm.WM_path, @name=TF+"_WM_tops_"+wmiter)
                  CandWM_i = std.lookup(TF+"_WM_tops_"+wmiter)

		  outvals = FGBGOUT[TF]
                  stets = GetWMStats(outvals.Sequences, outvals.TrainingSet, outvals.ShuffledTrainSet, outvals.RegionCoverageDir, outvals.PeakStats, CandWM_i.in, outvals.PeakCallDir, outvals.LLog_tops, outvals.AUCLog_tops, IP_string = TFrecordStrings[TF], @name=TF+"_WM_tops_stats_"+wmiter)
                  stets_i = std.lookup(TF+"_WM_tops_stats_"+wmiter)


	      }
	  }


 }



//////////////////////////////////////////////////////////////////////////////////

/*
else {

     // produce the final output without motifs (which is just the annotated peak file):
     for TF, peaks_tfbs : PEAKS_record{

         combinepeakstfbs = CombinePeaksTFBSs(peaks = peaks_tfbs["peaks"], minposterior=0.2, FGfiles_string=TFrecordStrings[TF], @name=TF+"_combinepeakstfbs")
         combinepeakstfbs_i = std.lookup(TF+"_combinepeakstfbs")
         OUTPUT(combinepeakstfbs_i.peaks_with_sites)
         }
}
*/


/*
         report = ConfigurationReport()
         latex = LatexCombiner(latex1 = report.report)
         template = LatexTemplate(authors="USER_NAME", title="Report TF_NAME")
         pdf = LatexPDF(document = latex.document, header=template.header, footer=template.footer) 
*/

