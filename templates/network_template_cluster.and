/*----------Composite Components-----------*/

/*----------Foreground Function------------*/
function IPfunction(BinaryFile IN, string repFMIid, string iter, string DESC, string TFname, string formatFlag) -> (BinaryFolder IPout, Latex IPlog)
{

    if formatFlag == "bed" {

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_file = IN, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                     capt_plot1="Fragment size correlation plot",
                                     sectionTitle=TFname+": Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)

       pdfreport = CombineLatex(latex1=latexfrag.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       return record(IPout=fraglen.out_dir, IPlog=latexfrag.fragment)

    }


    else {

       ////quality filtering, transform and importSample //////
       if formatFlag == "fastq" {
          //Quality Filter: Filters out reads that are too short and have too many Ns.
          qualityfilter = SilviaQF(in_file = IN, pythonPATH="PYTHON_PATH", @host="long"QUALITYFILTER_iter)

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = qualityfilter.out_file, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = qualityfilter.out_file, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)

          latexfrag1 = LatexFragmentizer(plot1=qualityfilter.plot_before,
                                         plot2=qualityfilter.plot_after,
                                         capt_plot1="Read length reverse cumulative distribution before filtering",
                                         capt_plot2="Read length reverse cumulative distribution after filtering",
                                         sectionTitle=TFname+": Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle="Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)



       }

       if formatFlag == "fasta" {

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = IN, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = IN, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle=TFname+": Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


       }


       //Imports the sample into FMI repository (copies the fasta file there and creates some directories).
       import = importSample(in_file = trans.out_file, desc=DESC, FMIpath="FMI_PATH", FMIid = repFMIid, perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @host="long_hm"IMPORT_iter) 


       ////work from the samples repository: annotateSample, extract wig and bed and count mappable reads //////////////

       //Runs bowtie to map to genome and transcriptome  
       annotate = annotateSample(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=import, @host="verylong_hm"ANNOTATE_iter)
  
       //Extracts mappings in bedweight format (weight is number of identical reads/number of mapping positions)
       bedweight = extractBedweight(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BEDWEIGHT_iter)

       //extracting bed format file. It's location is the same as bedweight.
       //bed = extractBed(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", maxhits=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BED_iter)

       //Extracts mappings in wig format
       wig = extractWig(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, width=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"WIG_iter)

       //Counts how many reads were mapped
       mappable = numberMappableReads(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"MAPPABLE_iter)

       //Creates three plots with mapping statistics
       errorPlots = createErrorPlots(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"ERRORPLOTS_iter)


       ////Shift bed file, output from bed_i

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_dir = bedweight.out_dir, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag4 = LatexFragmentizer(log1=mappable.numberMappableReads_log, 
                                      plot1=errorPlots.error_profiles_plot,
                                      plot2=errorPlots.fraction_aligned_plot,
                                      plot3=errorPlots.repeatedness_plot,
                                      capt_log1="Number of mapped reads", 
                                      capt_plot1="Fraction of all reads that had an error at read position",
                                      capt_plot2="Fraction of all reads that have a certain mapping error up to read position",
                                      capt_plot3="Number of reads that have a certain number of hits",
                                      sectionTitle="Mappging:", @host="noQueue"LATEXFRAG_iter)

       latexfrag5 = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                      capt_plot1="Fragment size correlation plot",
                                      sectionTitle="Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)


       if formatFlag == "fastq" {

       pdfreport = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }

       if formatFlag == "fasta" {

       pdfreport = CombineLatex(latex1=latexfrag2.fragment, latex2=latexfrag3.fragment, latex3=latexfrag4.fragment, latex4=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }


       return record(IPout=fraglen.out_dir, IPlog=latexfrag2.fragment)

    }

}


/*----------Background Function------------*/
function BGfunction(BinaryFile bgIN, string repFMIid, string iter, string DESC, string TFname, string formatFlag) -> (BinaryFolder BGout, Latex BGlog)
{

    if formatFlag == "bed" {

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_file = bgIN, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)

       latexfrag = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                     capt_plot1="Fragment size correlation plot",
                                     sectionTitle=TFname+": Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)

       pdfreport = CombineLatex(latex1=latexfrag.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       return record(BGout=fraglen.out_dir, BGlog=latexfrag.fragment)

    }


    else {

       ////quality filtering, transform and importSample //////
       if formatFlag == "fastq" {
          //Quality Filter: Filters out reads that are too short and have too many Ns.
          qualityfilter = SilviaQF(in_file = bgIN, pythonPATH="PYTHON_PATH", @host="long"QUALITYFILTER_iter)

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = qualityfilter.out_file, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = qualityfilter.out_file, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)

          latexfrag1 = LatexFragmentizer(plot1=qualityfilter.plot_before,
                                         plot2=qualityfilter.plot_after,
                                         capt_plot1="Read length reverse cumulative distribution before filtering",
                                         capt_plot2="Read length reverse cumulative distribution after filtering",
                                         sectionTitle=TFname+": Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle="Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)



       }

       if formatFlag == "fasta" {

          //Searches a subset of the input fasta file for matches with several adaptors and subwords thereof. The one adaptor with the most matches is given out.
          adaptor = adaptorDecision(in_file = bgIN, reads_number=250000, perlPATH="PERL_PATH", FMIpath="FMI_PATH", adapters="ADAPTERS_3", @host="long_hm"ADAPTOR_iter)

          //Removes the adaptor. If one is given in the parameter yaml file, this one is taken. Otherwise the one found by adaptorDecision is used.
          trans = transform(in_file = bgIN, adaptor3automatic = adaptor.finalAdaptor, adaptor3="NONE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", sortTMPDIR="SORT_TMPDIR", @host="long_hm"TRANS_iter)


          latexfrag2 = LatexFragmentizer(log1=adaptor.log_file,
                                         capt_log1="",
                                         plot1=adaptor.plot,
                                         capt_plot1="Plot for Adaptor Finding: Length of Adaptor versus Full Matches",
                                         sectionTitle=TFname+": Adaptor Finding:", @host="noQueue"LATEXFRAG_iter)


          latexfrag3 = LatexFragmentizer(log1=trans.transform_log,
                                         capt_log1="",
                                         sectionTitle="Adaptor Removal and Quality Filtering:", @host="noQueue"LATEXFRAG_iter)


       }


       //Imports the sample into FMI repository (copies the fasta file there and creates some directories).
       import = importSample(in_file = trans.out_file, desc=DESC, FMIpath="FMI_PATH", FMIid = repFMIid, perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @host="long_hm"IMPORT_iter) 


       ////work from the samples repository: annotateSample, extract wig and bed and count mappable reads //////////////

       //Runs bowtie to map to genome and transcriptome  
       annotate = annotateSample(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=import, @host="verylong_hm"ANNOTATE_iter)
  
       //Extracts mappings in bedweight format (weight is number of identical reads/number of mapping positions)
       bedweight = extractBedweight(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BEDWEIGHT_iter)

       //extracting bed format file. It's location is the same as bedweight.
       //bed = extractBed(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", maxhits=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"BED_iter)

       //Extracts mappings in wig format
       wig = extractWig(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", mismatches=100, width=100, FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"WIG_iter)

       //Counts how many reads were mapped
       mappable = numberMappableReads(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"MAPPABLE_iter)

       //Creates three plots with mapping statistics
       errorPlots = createErrorPlots(FMIid = repFMIid, annoType="ANNOTYPE", FMIpath="FMI_PATH", perlPATH="PERL_PATH", FMI_output_dir="FMI_OUTPUT_DIR", @bind=annotate, @host="sjpn_long_hm"ERRORPLOTS_iter)


       ////Shift bed file, output from bed_i

       //Tries to estimate a fragment length. It also shifts the reads by half fragment length upstream (+) or downstream (-)
       fraglen = FragmentLength(in_dir = bedweight.out_dir, repeatPath="REPEAT_PATH", perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", FMIpath="FMI_PATH", @host="long_hm"FRAGLEN_iter)


       latexfrag4 = LatexFragmentizer(log1=mappable.numberMappableReads_log, 
                                      plot1=errorPlots.error_profiles_plot,
                                      plot2=errorPlots.fraction_aligned_plot,
                                      plot3=errorPlots.repeatedness_plot,
                                      capt_log1="Number of mapped reads", 
                                      capt_plot1="Fraction of all reads that had an error at read position",
                                      capt_plot2="Fraction of all reads that have a certain mapping error up to read position",
                                      capt_plot3="Number of reads that have a certain number of hits",
                                      sectionTitle="Mappging:", @host="noQueue"LATEXFRAG_iter)

       latexfrag5 = LatexFragmentizer(plot1=fraglen.FragmentLength_plot, 
                                      capt_plot1="Fragment size correlation plot",
                                      sectionTitle="Fragment Size Estimation:", @host="noQueue"LATEXFRAG_iter)


       if formatFlag == "fastq" {

       pdfreport = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }

       if formatFlag == "fasta" {

       pdfreport = CombineLatex(latex1=latexfrag2.fragment, latex2=latexfrag3.fragment, latex3=latexfrag4.fragment, latex4=latexfrag5.fragment, @host="noQueue"PDFREPORT_iter)
       OUTPUT(pdfreport.pdfreport)

       }


       return record(BGout=fraglen.out_dir, BGlog=latexfrag2.fragment)


    }

}

/*-----------------------------------------------------------------------------------------------------------------*/
/*------------------------------Composite Component for processing on TF-Background pair---------------------------*/
/*-----------------------------------------------------------------------------------------------------------------*/

function FGBGprocessing(string IPstring, string BGstring, string WM, string TFname) -> (BinaryFile Sequences, BinaryFolder RegionCoverageDir, BinaryFile PeakStats, BinaryFolder PeakCallDir, BinaryFile LLog, BinaryFile LLog_tops, BinaryFile AUCLog, BinaryFile AUCLog_tops, BinaryFile Peaks, BinaryFile ShuffledTestSet, BinaryFile ShuffledTrainSet, BinaryFile TestSet, BinaryFile TrainingSet, BinaryFile UFEmodel, BinaryFile BaseFrequencies){

         //check whether a WM exists for this TF
	 if WM != "None" {
		wm_defined=1
                old_WM = INPUT(path=WM)
		}
         else {
                wm_defined=0
                }


         ////Doing all the read counting and BG cut-off filtering with Piotr's binReads.pl
         binreads = BinReads(FGfiles_string = IPstring, BGfiles_string = BGstring, chrominfo="CHROMINFOFILE_PATH", perlPATH="PERL_PATH", FGwinsize=FG_WINSIZE, BGwinsize=BG_WINSIZE, stepsize=STEPSIZE, FMIpath="FMI_PATH", @host="long_hm")

         bg_filter = FilterBGwin(infile = binreads.out_file, bg_cutoff=-99, perlPATH="PERL_PATH", @host="long_hm")

         peakcall_newnoise = PeakCall_newNoiseModel(in_file = bg_filter.outfile, perlPATH="PERL_PATH", R_LIBS_USER="R_LIBS_USER_PATH", @host="long_hm")

         //Find a cut-off on z-scores by constraining FDR
         find_z_cutoff = zCutOff_byFDR(in_dir = peakcall_newnoise.out_dir, FDR=FDRVALUE, @host="long")

         //Merges all overlapping widnows above a Z-value cut-off 
         peakmerge = PeakMerger(in_dir = peakcall_newnoise.out_dir, z_cutoff_infile = find_z_cutoff.z_cutoff_file, z_cutoff=-1, topPeaks=1000, @host="long")

         //Computes basepair coverage for each region (how many foreground reads voer each bp).
         regioncoverage = RegionCoverage(regions = peakmerge.allpeaks, read_files = IPstring, BedToolsPath="BEDTOOLS_PATH", regionlength=-1, toFraglength="true", @host="long_hm")

         //This thing will submit array jobs itself
	 //quene_name="long", here long stands for the actual queue name and nor for the alias from hosts.conf used by anduril!
         selectpeaks = SelectPeaksMM(in_dir = regioncoverage.out_dir, FGfiles_string=IPstring, FragmentLength=-1, files_per_job=50, order=4, widthFactor=1, project_leader="PROJECTLEADER", RMSD_cutoff=100, topPeaks=2000, queue_name="fs_long")


         //Recompute Z-scores for refined peaks
         recompz = RecomputeZscores(peakfile = selectpeaks.allpeaks, peakstats = selectpeaks.peakstats, binned_reads = bg_filter.outfile, fit_log = peakcall_newnoise.log_file, Z_cutoff_file = peakmerge.z_cutoff_file, read_files=IPstring, FGwinsize=FG_WINSIZE, Z_cutoff=-1, topPeaks=2000, @host="long_hm")


         repeatsout = RepeatsOut(peaks = recompz.outfile, repeatPath="REPEAT_PATH", BedToolsPath="BEDTOOLS_PATH", @host="long_hm")

         //annotate peaks to genes etc, do GO analysis etc... using HOMER
         //annotregions = AnnotateRegions(regions = recompz.allpeaks, genome="GENOME", homerPATH="HOMER_PATH", @host="long")
         
         //annotate peaks to promoters and thus to genes...
         annotpeaks = AnnotatePeaks(peaks = recompz.allpeaks, genome="GENOME", annotationFile="ANNOTATION_FILE", @host="long")

         pstats = recompz.peakstats

         //Aligns regions to some related species
         alignpeaks = AlignPeaks(in_file = repeatsout.out_file, genome="GENOME", AlignPipePath="ALIGN_PIPE_PATH")

         //Extracts sequences from region coordinates
         getseqs = GetSequences(in_file = repeatsout.out_file, genome="GENOME", genome_path="GENDIR_PATH", @host="long")

         //Splits alignments/sequences in two halfs. Both halfs have equally high Z-value scoring regions.
         splitalignments = SplitTestTrain(infile = alignpeaks.AlignedPeaks, @host="long")
         splitseqs = SplitTestTrain(infile = getseqs.Sequences, @host="long")

         //Shuffles Alignments/Sequences to produce a background.
         shuffledAlns_test = ShuffleAlignments(infile = splitalignments.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")
         shuffledAlns_train = ShuffleAlignments(infile = splitalignments.even_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")

         shuffledSeqs_test = ShuffleAlignments(infile = splitseqs.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")
         shuffledSeqs_train = ShuffleAlignments(infile = splitseqs.odd_file, mode="phil", iterations=10, perlPATH="PERL_PATH", pythonPATH="PYTHON_PATH", @host="long")


         //this is not really neccessary to assign outports to variables... it is an ancient thing. 
         shuffled_test_forreturn = shuffledSeqs_test.outfile
         shuffled_train_forreturn = shuffledSeqs_train.outfile
         test_forreturn = splitseqs.odd_file
         training_forreturn = splitseqs.even_file
         aligned_bool = "false"


         buildufe = BuildUFEmodel(Sequences = getseqs.Sequences, genome="GENOME", motevoUFE_path="MOTEVOUFE_PATH", @host="long")

         getseqs2 = GetSequences(in_file = peakmerge.allpeaks, genome="GENOME", genome_path="GENDIR_PATH", @host="long")


         //Fork here if no de novo motif finding is requested. If a WM is given it will be refined. Given WM and refined WM will be processed for WM statistics (GetWMStats) and also for a given WM library enrichment is checked and statistics for enriched WMs will be calculated.

         pipeFlag = "PIPEFLAG"

         if pipeFlag == "JUSTPEAKS" {
             
                  latexfrag1 = LatexFragmentizer(log1=bg_filter.log_file,
                                                 plot1=bg_filter.plotfile,
                                                 capt_log1="",
                                                 capt_log2="Reverse Cumulative Distribution of Background Window Counts.",
                                                 sectionTitle=TFname+": Filtering of Background Read Counts:")

                  latexfrag2 = LatexFragmentizer(log1=peakcall_newnoise.log_file,
                                                 plot1=peakcall_newnoise.Z_hist,
                                                 capt_log1="",
                                                 capt_plot1="Distribution of Window Z-values with Fitted Gaussian.",
                                                 sectionTitle="Fitting Background Noise Distribution:")

                  latexfrag3 = LatexFragmentizer(log1=peakmerge.PeakMerger_log,
                                                 plot1=find_z_cutoff.revcum,
                                                 capt_log1="",
                                                 capt_plot1="Reverse Cumulative Distribution of Window Z-values.",
                                                 sectionTitle="Determining Z-value Cut-off and Mergeing Windows:")

                  latexfrag4 = LatexFragmentizer(log1=selectpeaks.log_file,
                                                 plot1=selectpeaks.height_sigma_scatter,
                                                 //plot2=selectpeaks.height_rmsd_scatter,
                                                 //plot3=selectpeaks.sigma_rmsd_scatter,
                                                 plot4=selectpeaks.height_revcum,
                                                 //plot5=selectpeaks.rmsd_hist,
                                                 plot6=selectpeaks.sigma_hist,
                                                 capt_log1="",
                                                 capt_plot1="Scatter plot of peak height versus peak width",
                                                 //capt_plot2="Scatter plot of peak height versus peak quality",
                                                 //capt_plot3="Scatter plot of peak width versus peak quality",
                                                 capt_plot4="Reverse cumulative distribution of peak heights",
                                                 //capt_plot5="Histogram of peak qualities",
                                                 capt_plot6="Histogram of peak widths (sigmas)",
                                                 sectionTitle="Refining Peaks (Gaussian Mixture Modelling):")

                  latexfrag5 = LatexFragmentizer(log1=recompz.log_file,
                                                 plot1=recompz.height_z_scatter,
                                                 plot2=recompz.z_hist,
                                                 plot3=recompz.z_revcum,
                                                 capt_log1="",
                                                 capt_plot1="Scatter plot of peak height versus peak Z-score",
                                                 capt_plot2="Histogram of peak Z-scores",
                                                 capt_plot3="Reverse cumulative of peak Z-scores",
                                                 sectionTitle="Computing Z-scores of Refined Peaks:")

                  latexfrag6 = LatexFragmentizer(log1=annotpeaks.log_file,
                                                 capt_log1="",
                                                 sectionTitle="Annotating Refined Peaks:")


                  if wm_defined == 1 {

                     //Run motevo for refinement of existing weight matrix
                     runmotevo = RunMotevo(odd_file = splitseqs.odd_file, even_file = splitseqs.even_file, WM = old_WM.in, genome="GENOME", mylogo_path="MYLOGO_PATH", motevo_path="MOTEVO_PATH", minpostwm=0.25, wmdiff=0.000075, aligned="false", @host="long")


                     latexfragRef = LatexFragmentizer(plot1=runmotevo.Logo,
                                                      capt_plot1="Refined weight matrix logo.",
                                                      sectionTitle="Refining Given Motif:")



                     wmqual = WMQuality(train_set = splitseqs.even_file,
                                        bg_train_set = shuffledSeqs_train.outfile,
                                        test_set = splitseqs.odd_file,
                                        bg_test_set = shuffledSeqs_test.outfile,
                                        WM1 = old_WM.in,
                                        WM2 = runmotevo.refWM,
                                        aligned="false", genome="GENOME",
                                        motevo_path="MOTEVO_PATH",
                                        @host="long")


                     site_enrichment_slim = SiteEnrichmentM_greedy_drmaa(train_set = splitseqs.even_file,
                                                                         test_set = splitseqs.odd_file,
                                                                         bg_train_set = shuffledSeqs_train.outfile,
                                                                         background_set = shuffledSeqs_test.outfile,
                                                                         BaseFrequencies = buildufe.BaseFrequencies,
                                                                         WM1 = old_WM.in,
                                                                         WM2 = runmotevo.refWM,
                                                                         UFEmodel = buildufe.UFEmodel,
                                                                         genome="GENOME",
                                                                         motevo_path="MOTEVO_PATH",
                                                                         aligned=aligned_bool,
                                                                         slim="true",
                                                                         site_enrichment_cutoff=4.6,
                                                                         pseudocount=0.05,
                                                                         project_leader="PROJECTLEADER",
                                                                         queue_name="fs_long")


                     stetsOld = GetWMStats(Sequences = getseqs2.Sequences, RegionCoverage = regioncoverage.out_dir, PeakStats = pstats, CandWM = old_WM.in, PeakCallDir = peakcall_newnoise.out_dir,  LLog = site_enrichment_slim.loglik_all_motifs, AUCLog = wmqual.log_file, IP_string=IPstring)

                     stetsRef = GetWMStats(Sequences = getseqs2.Sequences, RegionCoverage = regioncoverage.out_dir, PeakStats = pstats, CandWM = runmotevo.refWM, PeakCallDir = peakcall_newnoise.out_dir,  LLog = site_enrichment_slim.loglik_all_motifs, AUCLog = wmqual.log_file, IP_string=IPstring)


                     combinepeakstfbs = CombinePeaksTFBSs_peaks(peaks = annotpeaks.peakAnnotations, peaks_known = stetsOld.Peakstats, peaks_refined = stetsRef.Peakstats, TFBSs_known = stetsOld.TFBSstats, TFBSs_refined = stetsRef.TFBSstats, known_name=WM, minposterior=0.2, FGfiles_string=IPstring, @host="long")


                     OUTPUT(combinepeakstfbs.peaks_with_sites)

                     combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment, latex7=latexfragRef.fragment)

                     OUTPUT(combine2.pdfreport)

                     //All these outports are dummies. (LLog and AUCLog ports could be used for TFBSstats of given and refined WM respectively.)
                     return record(Sequences = getseqs2.Sequences, RegionCoverageDir = regioncoverage.out_dir, PeakStats = pstats, PeakCallDir = peakcall_newnoise.out_dir, LLog = stetsOld.TFBSstats, LLog_tops = stetsOld.TFBSstats, AUCLog = stetsRef.TFBSstats, AUCLog_tops = stetsRef.TFBSstats, Peaks = annotpeaks.peakAnnotations, ShuffledTestSet = shuffledSeqs_test.outfile, ShuffledTrainSet = shuffledSeqs_train.outfile, TestSet = splitseqs.odd_file, TrainingSet = splitseqs.even_file, UFEmodel = buildufe.UFEmodel, BaseFrequencies = buildufe.BaseFrequencies)

                     }


                  else {

                        combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment)      
                        OUTPUT(combine2.pdfreport)
                        OUTPUT(annotpeaks.peakAnnotations)

			//All outports are dummy ports:
                        return record(Sequences = getseqs2.Sequences, RegionCoverageDir = regioncoverage.out_dir, PeakStats = pstats, PeakCallDir = peakcall_newnoise.out_dir, LLog = pstats, LLog_tops = pstats, AUCLog = pstats, AUCLog_tops = pstats, Peaks = annotpeaks.peakAnnotations, ShuffledTestSet = shuffledSeqs_test.outfile, ShuffledTrainSet = shuffledSeqs_train.outfile, TestSet = splitseqs.odd_file, TrainingSet = splitseqs.even_file, UFEmodel = buildufe.UFEmodel, BaseFrequencies = buildufe.BaseFrequencies)

                      }
           }


         //Runs PhyloGibbs
         phylogibbs1 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=10, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs2 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=15, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs3 =  RunPhyloGibbs(infile = splitalignments.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=20, numberWindows=-1, numberColours=2, AlignmentOrder=1, genome="GENOME", information_cutoff=0.25, @host="long")


/*phylogibbs without taking alignments into account*/

         phylogibbs4 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=10, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs5 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=15, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

         phylogibbs6 =  RunPhyloGibbs(infile = splitseqs.even_file, PhyloGibbsPATH="PHYLOGIBBS_PATH", mylogo_path="MYLOGO_PATH", markovorder=1, WindowLength=20, numberWindows=-1, numberColours=2, AlignmentOrder=0, genome="GENOME", information_cutoff=0.25, @host="long")

	 //Refine the resulted WMs from Phylogibbs
	 refinedMotifPG1_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs1.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG1_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs1.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG2_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs2.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG2_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs2.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG3_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs3.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG3_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs3.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG4_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs4.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG4_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs4.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG5_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs5.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG5_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs5.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG6_1 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs6.WeightMatrix1, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 refinedMotifPG6_2 = MotifRefinement(InputSequences=splitseqs.odd_file, WM=phylogibbs6.WeightMatrix2, genome="GENOME", @host="long", weblogo_path="WEBLOGO_PATH")
	 
	 //Fitting the background prior and beta over the training pool
	 fitPriorBetaPG1_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG1_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG1_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG1_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG2_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG2_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG2_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG2_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG3_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG3_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG3_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG3_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG4_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG4_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG4_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG4_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG5_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG5_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG5_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG5_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG6_1 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG6_1.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 fitPriorBetaPG6_2 = FitBackgroundPriorAndBeta(InputSequences=splitseqs.odd_file, DecoySequences=shuffledSeqs_test.outfile, WM=refinedMotifPG6_2.refWM, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")

	 //Calculating the enrichment scores over the test set by using the fitted paramters					    
	 enrichmentScoresPG1_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG1_1.refWM, FittedParams=fitPriorBetaPG1_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG1_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG1_2.refWM, FittedParams=fitPriorBetaPG1_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG2_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG2_1.refWM, FittedParams=fitPriorBetaPG2_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG2_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG2_2.refWM, FittedParams=fitPriorBetaPG2_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG3_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG3_1.refWM, FittedParams=fitPriorBetaPG3_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG3_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG3_2.refWM, FittedParams=fitPriorBetaPG3_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG4_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG4_1.refWM, FittedParams=fitPriorBetaPG4_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG4_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG4_2.refWM, FittedParams=fitPriorBetaPG4_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG5_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG5_1.refWM, FittedParams=fitPriorBetaPG5_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG5_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG5_2.refWM, FittedParams=fitPriorBetaPG5_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG6_1 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG6_1.refWM, FittedParams=fitPriorBetaPG6_1.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")
	 enrichmentScoresPG6_2 = CalculateEnrichmetScore(InputSequences=splitseqs.even_file, DecoySequences=shuffledSeqs_train.outfile, WM=refinedMotifPG6_2.refWM, FittedParams=fitPriorBetaPG6_2.FittedParameters, genome="GENOME", motevo_path="MOTEVO_PATH", @host="long")

         //Report generation

         latexfrag1 = LatexFragmentizer(log1=bg_filter.log_file,
                                        plot1=bg_filter.plotfile,
                                        capt_log1="",
                                        capt_log2="Reverse Cumulative Distribution of Background Window Counts.",
                                        sectionTitle=TFname+": Filtering of Background Read Counts:")

         latexfrag2 = LatexFragmentizer(log1=peakcall_newnoise.log_file,
                                        plot1=peakcall_newnoise.Z_hist,
                                        capt_log1="",
                                        capt_plot1="Distribution of Window Z-values with Fitted Gaussian.",
                                        sectionTitle="Fitting Background Noise Distribution:")

         latexfrag3 = LatexFragmentizer(log1=peakmerge.PeakMerger_log,
                                        plot1=find_z_cutoff.revcum,
                                        capt_log1="Bin Reads Log",
                                        capt_plot1="Reverse Cumulative Distribution of Window Z-values.",
                                        sectionTitle="Determining Z-value Cut-off and Mergeing Windows:")

         latexfrag4 = LatexFragmentizer(log1=selectpeaks.log_file,
                                        plot1=selectpeaks.height_sigma_scatter,
                                        //plot2=selectpeaks.height_rmsd_scatter,
                                        //plot3=selectpeaks.sigma_rmsd_scatter,
                                        plot4=selectpeaks.height_revcum,
                                        //plot5=selectpeaks.rmsd_hist,
                                        plot6=selectpeaks.sigma_hist,
                                        capt_log1="",
                                        capt_plot1="Scatter plot of peak height versus peak width",
                                        //capt_plot2="Scatter plot of peak height versus peak quality",
                                        //capt_plot3="Scatter plot of peak width versus peak quality",
                                        capt_plot4="Reverse cumulative distribution of peak heights",
                                        //capt_plot5="Histogram of peak qualities",
                                        capt_plot6="Histogram of peak widths (sigmas)",
                                        sectionTitle="Refining Peaks (Gaussian Mixture Modelling):")

         latexfrag5 = LatexFragmentizer(log1=recompz.log_file,
                                        plot1=recompz.height_z_scatter,
                                        plot2=recompz.z_hist,
                                        plot3=recompz.z_revcum,
                                        capt_log1="",
                                        capt_plot1="Scatter plot of peak height versus peak Z-score",
                                        capt_plot2="Histogram of peak Z-scores",
                                        capt_plot3="Reverse cumulative of peak Z-scores",
                                        sectionTitle="Computing Z-scores of Refined Peaks:")

         latexfrag6 = LatexFragmentizer(log1=annotpeaks.log_file,
                                        capt_log1="",
                                        sectionTitle="Annotating Refined Peaks:")

         latexfragPG = LatexFragmentizer(plot1=phylogibbs1.Logo1,
                                         plot2=phylogibbs1.Logo2,
                                         plot3=phylogibbs2.Logo1,
                                         plot4=phylogibbs2.Logo2,
                                         plot5=phylogibbs3.Logo1,
                                         plot6=phylogibbs3.Logo2,
                                         plot7=phylogibbs4.Logo1,
                                         plot8=phylogibbs4.Logo2,
                                         plot9=phylogibbs5.Logo1,
                                         plot10=phylogibbs5.Logo2,
                                         plot11=phylogibbs6.Logo1,
                                         plot12=phylogibbs6.Logo2,
                                         capt_plot1="Phylogibbs motif 1. Window length = 10, with alignments",
                                         capt_plot2="Phylogibbs motif 2. Window length = 10, with alignments",
                                         capt_plot3="Phylogibbs motif 3. Window length = 15, with alignments",
                                         capt_plot4="Phylogibbs motif 4. Window length = 15, with alignments",
                                         capt_plot5="Phylogibbs motif 5. Window length = 20, with alignments",
                                         capt_plot6="Phylogibbs motif 6. Window length = 20, with alignments",
                                         capt_plot7="Phylogibbs motif 7. Window length = 10, no alignments",
                                         capt_plot8="Phylogibbs motif 8. Window length = 10, no alignments",
                                         capt_plot9="Phylogibbs motif 9. Window length = 15, no alignments",
                                         capt_plot10="Phylogibbs motif 10. Window length = 15, no alignments",
                                         capt_plot11="Phylogibbs motif 11. Window length = 20, no alignments",
                                         capt_plot12="Phylogibbs motif 12. Window length = 20, no alignments",
                                         sectionTitle="Logos of All Twelve de novo Motifs:") 

         latexfragMot = LatexFragmentizer(plot1=refinedMotifPG1_1.Logo,
                                          plot2=refinedMotifPG1_2.Logo,
                                          plot3=refinedMotifPG2_1.Logo,
                                          plot4=refinedMotifPG2_2.Logo,
                                          plot5=refinedMotifPG3_1.Logo,
                                          plot6=refinedMotifPG3_2.Logo,
                                          plot7=refinedMotifPG4_1.Logo,
                                          plot8=refinedMotifPG4_2.Logo,
                                          plot9=refinedMotifPG5_1.Logo,
                                          plot10=refinedMotifPG5_2.Logo,
                                          plot11=refinedMotifPG6_1.Logo,
                                          plot12=refinedMotifPG6_2.Logo,
                                          capt_plot1="Refined logo for PhyloGibbs motif 1. Window length = 10, with alignments",
                                          capt_plot2="Refined logo for PhyloGibbs motif 2. Window length = 10, with alignments",
                                          capt_plot3="Refined logo for PhyloGibbs motif 3. Window length = 15, with alignments",
                                          capt_plot4="Refined logo for PhyloGibbs motif 4. Window length = 15, with alignments",
                                          capt_plot5="Refined logo for PhyloGibbs motif 5. Window length = 20, with alignments",
                                          capt_plot6="Refined logo for PhyloGibbs motif 6. Window length = 20, with alignments",
                                          capt_plot7="Refined logo for PhyloGibbs motif 7. Window length = 10, no alignments",
                                          capt_plot8="Refined logo for PhyloGibbs motif 8. Window length = 10, no alignments",
                                          capt_plot9="Refined logo for PhyloGibbs motif 9. Window length = 15, no alignments",
                                          capt_plot10="Refined logo for PhyloGibbs motif 10. Window length = 15, no alignments",
                                          capt_plot11="Refined logo for PhyloGibbs motif 11. Window length = 20, no alignments",
                                          capt_plot12="Refined logo for PhyloGibbs motif 12. Window length = 20, no alignments",
                                          sectionTitle="Logos for All Twelve Refined de novo Motifs.")


         if wm_defined == 1 {


            //Run motevo for refinement of existing weight matrix
            runmotevo = RunMotevo(odd_file = splitseqs.odd_file, even_file = splitseqs.even_file, WM = old_WM.in, shuffledPeaks = shuffledSeqs_test.outfile, genome="GENOME", mylogo_path="MYLOGO_PATH", motevo_path="MOTEVO_PATH", minpostwm=0.25, wmdiff=0.000075, aligned="false", @host="long")

            filterwms = FilterWMs(WM1 = phylogibbs1.WeightMatrix1,
                                  WM2 = refinedMotifPG1_1.refWM,
                                  WM3 = phylogibbs1.WeightMatrix2,
                                  WM4 = refinedMotifPG1_2.refWM,
                                  WM5 = phylogibbs2.WeightMatrix1,
                                  WM6 = refinedMotifPG2_1.refWM,
                                  WM7 = phylogibbs2.WeightMatrix2,
                                  WM8 = refinedMotifPG2_2.refWM,
                                  WM9 = phylogibbs3.WeightMatrix1,
                                  WM10 = refinedMotifPG3_1.refWM,
                                  WM11 = phylogibbs3.WeightMatrix2,
                                  WM12 = refinedMotifPG3_2.refWM,
                                  WM13 = phylogibbs4.WeightMatrix1,
                                  WM14 = refinedMotifPG4_1.refWM,
                                  WM15 = phylogibbs4.WeightMatrix2,
                                  WM16 = refinedMotifPG4_2.refWM,
                                  WM17 = phylogibbs5.WeightMatrix1,
                                  WM18 = refinedMotifPG5_1.refWM,
                                  WM19 = phylogibbs5.WeightMatrix2,
                                  WM20 = refinedMotifPG5_2.refWM,
                                  WM21 = phylogibbs6.WeightMatrix1,
                                  WM22 = refinedMotifPG6_1.refWM,
                                  WM23 = phylogibbs6.WeightMatrix2,
                                  WM24 = refinedMotifPG6_2.refWM,
                                  WM25 = runmotevo.refWM,
                                  @host="long")


            trimwm = TrimWM(WMdir = filterwms.WMdir,
                            information_cutoff=0.25,
                            @host="long")

	    enrichmentScores = EnrichmentScores(TrainingSequences=splitseqs.odd_file,
						TrainingDecoySequences=shuffledSeqs_train.outfile, 
						TestSequences=splitseqs.even_file, 
						TestDecoySequences=shuffledSeqs_test.outfile, 
						DenovoWMs=filterwms.WMdir, 
						DatabaseWMs=WMlib.in, 
						genome="GENOME")


            WMlibrary = "WMLIBRARY"
            WMlib = INPUT(path = WMlibrary)

            site_enrichment_slim = SiteEnrichmentM_greedy_drmaa(train_set = training_forreturn,
                                                                test_set = test_forreturn,
                                                                bg_train_set = shuffled_train_forreturn,
                                                                background_set = shuffled_test_forreturn,
                                                                BaseFrequencies = buildufe.BaseFrequencies,
                                                                WMdir = trimwm.outdir,
                                                                WMdir2 = filterwms.WMdir,
                                                                WMdir3 = WMlib.in,
                                                                UFEmodel = buildufe.UFEmodel,
                                                                genome="GENOME",
                                                                motevo_path="MOTEVO_PATH",
                                                                aligned=aligned_bool,
                                                                slim="true",
                                                                site_enrichment_cutoff=4.6,
                                                                pseudocount=0.05,
                                                                project_leader="PROJECTLEADER",
                                                                queue_name="fs_long",
								top_motifs=10)


            //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
            wmqual_tops = WMQuality(train_set = splitseqs.even_file,
                                    bg_train_set = shuffledSeqs_train.outfile,
                                    test_set = splitseqs.odd_file,
                                    bg_test_set = shuffledSeqs_test.outfile,
                                    WMlist = site_enrichment_slim.loglik_top_motifs,
                                    aligned="false", genome="GENOME",
                                    motevo_path="MOTEVO_PATH",
                                    @host="long")


            reducewms = ReduceWMs(infile = site_enrichment_slim.loglik_all_motifs,
                                  distance_cutoff=0.2,
                                  @host="long")



            site_enrichment = SiteEnrichmentM_greedy_drmaa(train_set = training_forreturn,
                                                           test_set = test_forreturn,
                                                           bg_train_set = shuffled_train_forreturn,
                                                           background_set = shuffled_test_forreturn,
                                                           BaseFrequencies = buildufe.BaseFrequencies,
                                                           keepWM = old_WM.in,
                                                           WMdir = reducewms.WMdir,
                                                           UFEmodel = buildufe.UFEmodel,
                                                           genome="GENOME",
                                                           motevo_path="MOTEVO_PATH",
                                                           aligned=aligned_bool,
                                                           slim="false",
                                                           site_enrichment_cutoff=4.6,
                                                           pseudocount=0.05,
                                                           project_leader="PROJECTLEADER",
                                                           queue_name="fs_long")



            //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
            wmqual = WMQuality(train_set = splitseqs.even_file,
                               bg_train_set = shuffledSeqs_train.outfile,
                               test_set = splitseqs.odd_file,
                               bg_test_set = shuffledSeqs_test.outfile,
                               WMlist = site_enrichment.loglik_contributing_motifs,
                               aligned="false", genome="GENOME",
                               motevo_path="MOTEVO_PATH",
                               @host="long")



            latexfrag7 = LatexFragmentizer(plot1=runmotevo.Logo,
                                           capt_plot1="Refined weight matrix logo.",
                                           sectionTitle="Log for Refinement of Known Motif:")

            latexfrag8 = LatexFragmentizer(plot1=wmqual.sens_ppv,
                                           capt_plot1="Sensitivity - positive predictive value plot of 4 best performing motifs",
                                           sectionTitle="Precision and Recall Plots of Four Best Performing Motifs:")


            latexfrag9 = LatexFragmentizer(//log1=site_enrichment.loglik_combined,
                                           plot1=site_enrichment.loglik_plot,
                                           //capt_log1="",
                                           capt_plot1="Contribution of motifs to ChIP peak explanantion.",
                                           sectionTitle="Final Motifs and Their Contribution in Explaining the Peaks:")



            combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment, latex7=latexfragPG.fragment, latex8=latexfragMot.fragment, latex9=latexfrag7.fragment, latex10=latexfrag8.fragment, latex11=latexfrag9.fragment)
            OUTPUT(combine2.pdfreport)


         } 


         else {


            filterwms = FilterWMs(WM1 = phylogibbs1.WeightMatrix1,
                                  WM2 = refinedMotifPG1_1.refWM,
                                  WM3 = phylogibbs1.WeightMatrix2,
                                  WM4 = refinedMotifPG1_2.refWM,
                                  WM5 = phylogibbs2.WeightMatrix1,
                                  WM6 = refinedMotifPG2_1.refWM,
                                  WM7 = phylogibbs2.WeightMatrix2,
                                  WM8 = refinedMotifPG2_2.refWM,
                                  WM9 = phylogibbs3.WeightMatrix1,
                                  WM10 = refinedMotifPG3_1.refWM,
                                  WM11 = phylogibbs3.WeightMatrix2,
                                  WM12 = refinedMotifPG3_2.refWM,
                                  WM13 = phylogibbs4.WeightMatrix1,
                                  WM14 = refinedMotifPG4_1.refWM,
                                  WM15 = phylogibbs4.WeightMatrix2,
                                  WM16 = refinedMotifPG4_2.refWM,
                                  WM17 = phylogibbs5.WeightMatrix1,
                                  WM18 = refinedMotifPG5_1.refWM,
                                  WM19 = phylogibbs5.WeightMatrix2,
                                  WM20 = refinedMotifPG5_2.refWM,
                                  WM21 = phylogibbs6.WeightMatrix1,
                                  WM22 = refinedMotifPG6_1.refWM,
                                  WM23 = phylogibbs6.WeightMatrix2,
                                  WM24 = refinedMotifPG6_2.refWM,
                                  @host="long")

            trimwm = TrimWM(WMdir = filterwms.WMdir,
                            information_cutoff=0.25,
                            @host="long")
	
	    
	    enrichmentScores = EnrichmentScores(TrainingSequences=splitseqs.odd_file,
						TrainingDecoySequences=shuffledSeqs_train.outfile, 
						TestSequences=splitseqs.even_file, 
						TestDecoySequences=shuffledSeqs_test.outfile, 
						DenovoWMs=filterwms.WMdir, 
						DatabaseWMs=WMlib.in, 
						genome="GENOME")



            WMlibrary = "WMLIBRARY"
            WMlib = INPUT(path = WMlibrary)

            site_enrichment_slim = SiteEnrichmentM_greedy_drmaa(train_set = training_forreturn,
                                                                test_set = test_forreturn,
                                                                bg_train_set = shuffled_train_forreturn,
                                                                background_set = shuffled_test_forreturn,
                                                                BaseFrequencies = buildufe.BaseFrequencies,
                                                                WMdir = trimwm.outdir,
                                                                WMdir2 = filterwms.WMdir,
                                                                WMdir3 = WMlib.in,
                                                                UFEmodel = buildufe.UFEmodel,
                                                                genome="GENOME",
                                                                motevo_path="MOTEVO_PATH",
                                                                aligned=aligned_bool,
                                                                slim="true",
                                                                site_enrichment_cutoff=4.6,
                                                                pseudocount=0.05,
                                                                project_leader="PROJECTLEADER",
                                                                queue_name="fs_long",
								top_motifs=10)

            //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
            wmqual_tops = WMQuality(train_set = splitseqs.even_file,
                                    bg_train_set = shuffledSeqs_train.outfile,
                                    test_set = splitseqs.odd_file,
                                    bg_test_set = shuffledSeqs_test.outfile,
                                    WMlist = site_enrichment_slim.loglik_top_motifs,
                               	    aligned="false", genome="GENOME",
                               	    motevo_path="MOTEVO_PATH",
                               	    @host="long")

            reducewms = ReduceWMs(infile = site_enrichment_slim.loglik_all_motifs,
                                  distance_cutoff=0.2,
                                  @host="long")


            site_enrichment = SiteEnrichmentM_greedy_drmaa(train_set = training_forreturn,
                                                           test_set = test_forreturn,
                                                           bg_train_set = shuffled_train_forreturn,
                                                           background_set = shuffled_test_forreturn,
                                                           BaseFrequencies = buildufe.BaseFrequencies,
                                                           WMdir = reducewms.WMdir,
                                                           UFEmodel = buildufe.UFEmodel,
                                                           genome="GENOME",
                                                           motevo_path="MOTEVO_PATH",
                                                           aligned=aligned_bool,
                                                           slim="false",
                                                           site_enrichment_cutoff=4.6,
                                                           pseudocount=0.05,
                                                           project_leader="PROJECTLEADER",
                                                           queue_name="fs_long")



            //take one set of alignments and background alignments to test all WMs we have. Also gives the best WM.
            wmqual = WMQuality(train_set = splitseqs.even_file,
                               bg_train_set = shuffledSeqs_train.outfile,
                               test_set = splitseqs.odd_file,
                               bg_test_set = shuffledSeqs_test.outfile,
                               WMlist = site_enrichment.loglik_contributing_motifs,
                               aligned="false", genome="GENOME",
                               motevo_path="MOTEVO_PATH",
                               @host="long")


            latexfrag8 = LatexFragmentizer(plot1=wmqual.sens_ppv,
                                           capt_plot1="Sensitivity - positive predictive value plot of 4 best performing motifs",
                                           sectionTitle="Precision and Recall Plots of Four Best Performing Motifs:")


            latexfrag9 = LatexFragmentizer(//log1=site_enrichment.loglik_combined,
                                           plot1=site_enrichment.loglik_plot,
                                           //capt_log1="",
                                           capt_plot1="Contribution of motifs to ChIP peak explanantion.",
                                           sectionTitle="Final Motifs and Their Contribution in Explaining the Peaks:")



            combine2 = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment, latex3=latexfrag3.fragment, latex4=latexfrag4.fragment, latex5=latexfrag5.fragment, latex6=latexfrag6.fragment, latex7=latexfragPG.fragment, latex8=latexfragMot.fragment, latex9=latexfrag8.fragment, latex10=latexfrag9.fragment)
            OUTPUT(combine2.pdfreport)



         }


         return record(Sequences = getseqs2.Sequences, RegionCoverageDir = regioncoverage.out_dir, PeakStats = pstats, PeakCallDir = peakcall_newnoise.out_dir, LLog = site_enrichment.loglik_contributing_motifs, LLog_tops = site_enrichment_slim.loglik_top_motifs, AUCLog = wmqual.log_file, AUCLog_tops = wmqual_tops.log_file, Peaks = annotpeaks.peakAnnotations, ShuffledTestSet = shuffledSeqs_test.outfile, ShuffledTrainSet = shuffledSeqs_train.outfile, TestSet = splitseqs.odd_file, TrainingSet = splitseqs.even_file, UFEmodel = buildufe.UFEmodel, BaseFrequencies = buildufe.BaseFrequencies)


}


/*-----------------------------------------------------------------------------------------------------------------*/
/*-----------------------Composite Component to compute statistics for each candidate WM---------------------------*/
/*-----------------------------------------------------------------------------------------------------------------*/



function GetWMStats(BinaryFile Sequences, BinaryFile TrainingSet, BinaryFile ShuffledTrainSet, BinaryFolder RegionCoverage, BinaryFile PeakStats, BinaryFile CandWM, BinaryFolder PeakCallDir, BinaryFile LLog, BinaryFile AUCLog, string IP_string) -> (BinaryFile Peakstats, BinaryFile TFBSstats) {


             WMlibrary = "WMLIBRARY"

             identifymotif = IdentifyMotif(WM = CandWM, WMlibrary=WMlibrary, ntop=4, mylogo_path="MYLOGO_PATH", @host="long")

             createlogo = CreateLogo(WM = CandWM, llog = LLog, auclog = AUCLog, mylogo_path="MYLOGO_PATH")

             getpeakposts = GetPeakPosteriors(regions = Sequences, 
                                              train_set = TrainingSet,
                                              bg_train_set = ShuffledTrainSet,
                                              RegCov_dir = RegionCoverage,
                                              statsfile = PeakStats,
                                              WM = CandWM,
                                              minposterior=0.2, motevo_path="MOTEVO_PATH", genome="GENOME", project_leader="PROJECTLEADER", files_per_job=1000,
                                              read_files=IP_string,
                                              queue_name_motevo="fs_long@@x3755",
                                              queue_name="fs_long@@x3755")


             getstats = GetStatistics(peakstats = getpeakposts.peakstats, TFBSstats = getpeakposts.TFBSstats, RegCov_dir = RegionCoverage, minposterior=0.2, @host="long")


             latexfrag1 = LatexFragmentizer(log1=identifymotif.top_motifs,
                                            log2=createlogo.log_file,
                                            plot1=createlogo.Logo,
                                            plot2=createlogo.sens_spec,
                                            capt_log1="4 Top Similar Looking Motifs:",
                                            capt_log2="Statistics:",
                                            capt_plot1="Logo of Weight Matrix",
                                            capt_plot2="Precision and Recall curve",
                                            sectionTitle="General Motif Characteristics:")

             latexfrag2 = LatexFragmentizer(log1=getstats.log_file,
                                            plot1=getstats.zscore_post_scatter,
                                            //plot2=getstats.quality_post_scatter,
                                            plot3=getstats.zscore_post_violin,
                                            //plot4=getstats.quality_post_violin,
                                            plot5=getstats.post_hist,
                                            //plot6=getstats.post_cumulative,
                                            plot7=getstats.TFBS_peakcenter_dist_hist,
                                            //plot8=getstats.TFBS_post_peakcenter_dist_scatter,
                                            plot9=getstats.coverage_histograms,
                                            capt_log3="",
                                            capt_plot1="Scatter plot of peak Z-score versus number of binding sites at peak",
                                            //capt_plot2="Scatter plot of peak quality versus number of binding sites at peak",
                                            capt_plot3="Violin plot of peak Z-score versus number of binding sites at peak",
                                            //capt_plot4="Violin plot of peak quality versus number of binding sites at peak",
                                            capt_plot5="Histogram of number of binding sites at peaks",
                                            //capt_plot6="Cumulative distribution of number of binding sites at peaks",
                                            capt_plot7="Histogram of distances of TFBS to its nearest peak center",
                                            //capt_plot8="Scatter plot of TFBS posterior versus distance to its nearest peak center",
                                            capt_plot9="Histograms of coverage at sites and in total regions",
                                            sectionTitle="Statistics for TFBS - Peak Centering and Peak Posterior - Peak Height Correlation:")



             combineWM = CombineLatex(latex1=latexfrag1.fragment, latex2=latexfrag2.fragment) //, latex4=latexfrag4.fragment)

             OUTPUT(combineWM.pdfreport)

             return record(Peakstats = getpeakposts.peakstats, TFBSstats = getpeakposts.TFBSstats)

}



/*----------------------------------------------------------------------------------------------------------------------------------*/
/*----------------------------------------------------Main function-----------------------------------------------------------------*/
/*----------------------------------------------------------------------------------------------------------------------------------*/


/*----------------1. Read in data--------------------*/

datafiles = INPUT(path="CSV_DATAFILE_PATH")
existingSamples = INPUT(path="CSV_EXISTING_SAMPLES")


TFrecord = record() 
TFrecordStrings = record() //This is the record for already processed replicates. The strings are thus shifted bedweight files
WMdict = record()  //contains all WMs for all TFs, if they exist

//Add the BG key, in case there is no background given. Otherwise it will complain below when starting FGBGprocessing.
TFrecordStrings["BG"] = ""
  
//initialize TFrecordString (contains string with paths to the shifted bedfiles)
//initilaize TFrecord with records for each input replicate
//initialize WMdict

for file : std.itercsv(datafiles.in){
	TFrecordStrings[file.mode] = ""
	TFrecord[file.mode] = record()   
        WMdict[file.mode] = file.WM
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))

////Reading from existingSamples.csv to add shifted.bedweight files to corresponding string.
for file : std.itercsv(existingSamples.in){
           TFrecordStrings[file.mode] = ""
           TFrecord[file.mode] = record()
           WMdict[file.mode] = file.WM
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))

for file : std.itercsv(existingSamples.in){
           TFrecordStrings[file.mode] = TFrecordStrings[file.mode] + file.filepath + " "
}

//std.echo(std.recordToString(TFrecord))
//std.echo(std.recordToString(TFrecordStrings))


/*----------------2. process replicates, i.e. get shifted bedweight files--------------------*/

ip = 0
bg = 0

count_record = record()
//initialize count record. I need count_record so that every TF gets numbered from 1 onwards.
for file: std.itercsv(datafiles.in){
          count_record[file.mode] = 0
          }

for file : std.itercsv(datafiles.in){
	if file.mode != "BG" {
		count_record[file.mode] = count_record[file.mode] + 1
                ip = ip + 1

                fastq = INPUT(path=file.filepath, @name="fastq"+ip)
                fastq_i = std.lookup("fastq"+ip)

		IP = IPfunction(fastq_i.in, repFMIid = file.FMIid, iter = "IP"+ip, DESC = file.desc, TFname=file.mode, formatFlag=file.format, @name=file.mode + "_" + count_record[file.mode])
		IP_i = std.lookup(file.mode + "_" + count_record[file.mode])

		TFrecord[file.mode][ip] = IP_i.IPout

		}

	else {
		bg = bg + 1
		bg_fastq = INPUT(path=file.filepath, @name="bg_fastq"+bg)
                bg_fastq_i = std.lookup("bg_fastq"+bg)

		BG = BGfunction(bg_fastq_i.in, repFMIid = file.FMIid, iter = "BG"+bg, DESC = file.desc, TFname="Background", formatFlag=file.format, @name=file.mode + "_" + bg)
		BG_i = std.lookup(file.mode + "_" + bg)
 
		TFrecord[file.mode][bg] = BG_i.BGout

		}
}

//putting all shifted bedweight file paths from TFrecord into TFrecordStrings
for key, value : TFrecord{

	for key1, value1 : value{

		for k : std.iterdir(value1){
			TFrecordStrings[key] = TFrecordStrings[key] + " " + k.path
			}
		}
	}



/*-----------3. Start downstream processing of foreground and background samples------------*/

/*-------3.1 First find peaks and candidate WMs---------*/

FGBGOUT = record()
PEAKS_record = record()
for TF, str : TFrecordStrings{
	if TF != "BG"{
		proc = FGBGprocessing(IPstring = str, BGstring = TFrecordStrings["BG"], WM = WMdict[TF], TFname = TF, @name=TF + "_FgBg")
		proc_i = std.lookup(TF + "_FgBg")
		FGBGOUT[TF] = proc_i

                PEAKS_record[TF] = record()
                PEAKS_record[TF]["peaks"] = proc_i.Peaks

		}
	}

std.echo(std.recordToString(FGBGOUT))

pipeFlag = "PIPEFLAG"

//always use non aligned peaks, i.e. sequences
aligned_flag = "false"


/*-------3.2 Now get statistics for candidate WMs (de novo motifs) if requested---------*/

if pipeFlag != "JUSTPEAKS" {

          for TF, outvals : FGBGOUT{

              //To enable the pipe-line to run this loop parallely, first collect output and later parse it.
              Peak_stats_record = {}
              TFBSs_stats_record = {}

              wmiter = 0

              for candwm : std.itercsv(outvals.LLog){
        
                wmiter = wmiter + 1

                CandWM = INPUT(path=candwm.WM_path, @name=TF+"_WM_"+wmiter)
                CandWM_i = std.lookup(TF+"_WM_"+wmiter)


                stets = GetWMStats(outvals.Sequences, outvals.TrainingSet, outvals.ShuffledTrainSet, outvals.RegionCoverageDir, outvals.PeakStats, CandWM_i.in, outvals.PeakCallDir, outvals.LLog, outvals.AUCLog, IP_string = TFrecordStrings[TF], @name=TF+"_WMstats_"+wmiter)
                stets_i = std.lookup(TF+"_WMstats_"+wmiter)

                Peak_stats_record[candwm.WM_path] = stets_i.Peakstats
                TFBSs_stats_record[candwm.WM_path] = stets_i.TFBSstats

              }

              //used to plot correlation of predictions and to combine sites of all motifs in peak file.
              Peak_stats_record_strings = {}
              for wmpath, wmport : Peak_stats_record{
		  for k : std.iterdir(wmport){
                      Peak_stats_record_strings[wmpath] = k.path + "/" + k.name
                  }
              }
              Peak_stats_string = std.recordToString(Peak_stats_record_strings, valueSep=" ", itemSep=" ; ", keys=true, values=true)

              TFBSs_stats_record_strings = {}
              for wmpath, wmport : TFBSs_stats_record{
                  for k : std.iterdir(wmport){
                      TFBSs_stats_record_strings[wmpath] = k.path + "/" + k.name
                  }
              }
              TFBSs_string = std.recordToString(TFBSs_stats_record_strings, valueSep=" ", itemSep=" ; ", keys=true, values=true)

              PEAKS_record[TF]["peakstats"] = Peak_stats_string
              PEAKS_record[TF]["tfbs"] = TFBSs_string

          }


          for TF, peaks_tfbs : PEAKS_record{

              // produce the final output file just with known motifs:

              combinepeakstfbs = CombinePeaksTFBSs(peaks = peaks_tfbs["peaks"], TFBSs_string=peaks_tfbs["tfbs"], peakposts_string=peaks_tfbs["peakstats"], minposterior=0.2, FGfiles_string=TFrecordStrings[TF], @host="long", @name=TF+"_combinepeakstfbs")
              combinepeakstfbs_i = std.lookup(TF+"_combinepeakstfbs")

              motif_correlation = MotifCorrelation(peakstats_string = peaks_tfbs["peakstats"], @host="long", @name=TF+"_motif_correlation")
              motif_correlation_i = std.lookup(TF+"_motif_correlation")
              OUTPUT(motif_correlation_i.correlation_plot)
          }


          for TF, outvals : FGBGOUT{

	      wmiter = 0

	      for candwm : std.itercsv(outvals.LLog_tops) {
	      	  wmiter = wmiter + 1

                  CandWM = INPUT(path=candwm.WM_path, @name=TF+"_WM_tops_"+wmiter)
                  CandWM_i = std.lookup(TF+"_WM_tops_"+wmiter)

		  outvals = FGBGOUT[TF]
                  stets = GetWMStats(outvals.Sequences, outvals.TrainingSet, outvals.ShuffledTrainSet, outvals.RegionCoverageDir, outvals.PeakStats, CandWM_i.in, outvals.PeakCallDir, outvals.LLog_tops, outvals.AUCLog_tops, IP_string = TFrecordStrings[TF], @name=TF+"_WM_tops_stats_"+wmiter)
                  stets_i = std.lookup(TF+"_WM_tops_stats_"+wmiter)


	      }
	  }


 }



//////////////////////////////////////////////////////////////////////////////////

/*
else {

     // produce the final output without motifs (which is just the annotated peak file):
     for TF, peaks_tfbs : PEAKS_record{

         combinepeakstfbs = CombinePeaksTFBSs(peaks = peaks_tfbs["peaks"], minposterior=0.2, FGfiles_string=TFrecordStrings[TF], @name=TF+"_combinepeakstfbs")
         combinepeakstfbs_i = std.lookup(TF+"_combinepeakstfbs")
         OUTPUT(combinepeakstfbs_i.peaks_with_sites)
         }
}
*/


/*
         report = ConfigurationReport()
         latex = LatexCombiner(latex1 = report.report)
         template = LatexTemplate(authors="USER_NAME", title="Report TF_NAME")
         pdf = LatexPDF(document = latex.document, header=template.header, footer=template.footer) 
*/

